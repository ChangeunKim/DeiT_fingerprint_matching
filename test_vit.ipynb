{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44477,
     "status": "ok",
     "timestamp": 1730421172483,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "5cCQExteXKcs",
    "outputId": "2d1cbcc6-5ac3-4620-9cfe-ae27909e7ce3"
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install kagglehub\n",
    "!pip install scikit-learn\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34581,
     "status": "ok",
     "timestamp": 1730421207062,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "YBK5SmPGXKcu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from itertools import combinations\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import GradScaler, autocast\n",
    "import timm\n",
    "from torchvision import models, transforms\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730421207063,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "mlCtdOvvXKcu"
   },
   "outputs": [],
   "source": [
    "def create_image_pairs_labels(dataset_dir, num_impostor_pairs=1000):\n",
    "    # Dictionary to organize images by user and finger type\n",
    "    user_finger_dict = {}\n",
    "\n",
    "    # Step 1: Parse filenames and organize by user ID and finger type\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        if filename.endswith(\".BMP\"):\n",
    "            parts = filename.split(\"__\")  # Splitting by double underscore\n",
    "            user_num = parts[0]\n",
    "            finger_type = parts[1].rsplit(\"_\", 1)[0]  # Extracting finger info without augmentation part\n",
    "\n",
    "            # Add to dictionary\n",
    "            if (user_num, finger_type) not in user_finger_dict:\n",
    "                user_finger_dict[(user_num, finger_type)] = []\n",
    "            user_finger_dict[(user_num, finger_type)].append(os.path.join(dataset_dir, filename))\n",
    "\n",
    "    image_pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # Step 2: Create genuine pairs (same user, same finger)\n",
    "    for _, images in user_finger_dict.items():\n",
    "        if len(images) > 1:\n",
    "            for img1, img2 in combinations(images, 2):\n",
    "                image_pairs.append((img1, img2))\n",
    "                labels.append(1)  # 1 for genuine pairs\n",
    "\n",
    "    # Step 3: Create impostor pairs (different user or different finger)\n",
    "    user_finger_keys = list(user_finger_dict.keys())\n",
    "    num_pairs = 0\n",
    "\n",
    "    while num_pairs < num_impostor_pairs:\n",
    "        user_finger1, user_finger2 = random.sample(user_finger_keys, 2)\n",
    "\n",
    "        # Ensure different user or finger type\n",
    "        if user_finger1[0] != user_finger2[0] or user_finger1[1] != user_finger2[1]:\n",
    "            img1 = random.choice(user_finger_dict[user_finger1])\n",
    "            img2 = random.choice(user_finger_dict[user_finger2])\n",
    "            image_pairs.append((img1, img2))\n",
    "            labels.append(-1)  # -1 for impostor pairs\n",
    "            num_pairs += 1\n",
    "\n",
    "    return image_pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730421207063,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "ek3xW400XKcv"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset for Siamese Network\n",
    "class SiameseFingerprintDataset(Dataset):\n",
    "    def __init__(self, image_pairs, labels, transform=None):\n",
    "        self.image_pairs = image_pairs\n",
    "        self.labels = labels\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load images from file paths\n",
    "        img1_path, img2_path = self.image_pairs[index]\n",
    "        img1 = Image.open(img1_path).convert(\"RGB\")  # Ensure 3 channels\n",
    "        img2 = Image.open(img2_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations\n",
    "        img1 = self.transform(img1)\n",
    "        img2 = self.transform(img2)\n",
    "\n",
    "        # Get label\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "\n",
    "        return img1, img2, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1730421343045,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "NWqbII0xXKcv"
   },
   "outputs": [],
   "source": [
    "class SiameseDeiTTiny(nn.Module):\n",
    "    def __init__(self, embedding = 64):\n",
    "        super(SiameseDeiTTiny, self).__init__()\n",
    "        self.deit = timm.create_model('deit_tiny_patch16_224', pretrained=True)\n",
    "\n",
    "        # Get the number of features from the previous layer\n",
    "        num_features = self.deit.head.in_features\n",
    "\n",
    "        # Remove the original classification head\n",
    "        self.deit.head = None\n",
    "\n",
    "        # Add a new fully connected layer with the desired embedding dimension\n",
    "        self.deit.head = nn.Linear(num_features, embedding)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        embed1 = self.deit(img1)\n",
    "        embed2 = self.deit(img2)\n",
    "        return embed1, embed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730421207063,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "XkM5JBrfhOBT"
   },
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def calculate_far_frr(predictions, labels, threshold=0.5):\n",
    "    true_positives = ((predictions >= threshold) & (labels == 1)).sum().item()\n",
    "    false_positives = ((predictions >= threshold) & (labels == 0)).sum().item()\n",
    "    true_negatives = ((predictions < threshold) & (labels == 0)).sum().item()\n",
    "    false_negatives = ((predictions < threshold) & (labels == 1)).sum().item()\n",
    "\n",
    "    far = false_positives / (false_positives + true_negatives) if (false_positives + true_negatives) > 0 else 0\n",
    "    frr = false_negatives / (false_negatives + true_positives) if (false_negatives + true_positives) > 0 else 0\n",
    "\n",
    "    return far, frr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730421207063,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "CCRfe9_eZAI0"
   },
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for img1, img2, label in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=False):\n",
    "          img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          # Runs the forward pass with autocasting.\n",
    "          with autocast(device_type=device, dtype=torch.float16):\n",
    "            # Forward pass\n",
    "            embed1, embed2 = model(img1, img2)\n",
    "            loss = criterion(embed1, embed2, label.float())\n",
    "\n",
    "          # Backward pass and optimization\n",
    "          scaler.scale(loss).backward()\n",
    "          scaler.step(optimizer)\n",
    "          scaler.update()\n",
    "\n",
    "          total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Testing Function\n",
    "def test_model(model, test_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    embeddings1 = []\n",
    "    embeddings2 = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, label in  tqdm(test_loader, leave=False):\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "            embed1, embed2 = model(img1, img2)\n",
    "            embeddings1.append(embed1)\n",
    "            embeddings2.append(embed2)\n",
    "            labels.extend(label.cpu().numpy())\n",
    "\n",
    "    embeddings1 = torch.cat(embeddings1)\n",
    "    embeddings2 = torch.cat(embeddings2)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    similarities = F.cosine_similarity(embeddings1, embeddings2)\n",
    "    predictions = (similarities >= threshold).float()\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    far, frr = calculate_far_frr(predictions, labels, threshold)\n",
    "\n",
    "    return accuracy, far, frr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57745,
     "status": "ok",
     "timestamp": 1730421264805,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "rHZIlrOKXKcv",
    "outputId": "c446fe58-30fa-41ef-fcde-fb31011f49a5"
   },
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ruizgara/socofing\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1730421264805,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "8Ku0srpdXKcv"
   },
   "outputs": [],
   "source": [
    "path_easy = os.path.join(path, 'SOCOFing/Altered/Altered-Easy')\n",
    "path_medium = os.path.join(path, 'SOCOFing/Altered/Altered-Medium')\n",
    "path_hard = os.path.join(path, 'SOCOFing/Altered/Altered-Hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1730421265430,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "cqk6PVrkXKcw"
   },
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "hard_image_pairs, hard_labels = create_image_pairs_labels(path_hard, num_impostor_pairs=20000)\n",
    "medium_image_pairs, medium_labels = create_image_pairs_labels(path_medium, num_impostor_pairs=20000)\n",
    "easy_image_pairs, easy_labels = create_image_pairs_labels(path_easy, num_impostor_pairs=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730421265430,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "-NPgX0rVdPkT"
   },
   "outputs": [],
   "source": [
    "image_pairs = hard_image_pairs + medium_image_pairs + easy_image_pairs\n",
    "labels = hard_labels + medium_labels + easy_labels\n",
    "\n",
    "train_size = int(0.8 * len(image_pairs))\n",
    "test_size = len(image_pairs) - train_size\n",
    "\n",
    "train_image_pairs, test_image_pairs = image_pairs[:train_size], image_pairs[train_size:]\n",
    "train_labels, test_labels = labels[:train_size], labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730421265431,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "Xc0LkTU_cEW0"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 1e-4\n",
    "batch_size = 512\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730421265431,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "7PBVSUCqXKcw",
    "outputId": "4bb42bfa-68e9-45eb-9884-5c58e8919fb8"
   },
   "outputs": [],
   "source": [
    "train_dataset = SiameseFingerprintDataset(train_image_pairs, train_labels)\n",
    "test_dataset = SiameseFingerprintDataset(test_image_pairs, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730421265431,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "uBkkPrlutWVL",
    "outputId": "cc0c1f1a-b3c1-4b39-f47d-569f3a79b330"
   },
   "outputs": [],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1730421348567,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "AEADNFmbXKcw"
   },
   "outputs": [],
   "source": [
    " # Initialize Model, Loss, and Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SiameseDeiTTiny().to(device)\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emqU7voGXKcw",
    "outputId": "1c2ea05f-a385-4249-eb9d-c843199e03ce"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting Training...\")\n",
    "train(model, train_loader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1730421267153,
     "user": {
      "displayName": "김창은changeun120",
      "userId": "10662965755131775786"
     },
     "user_tz": -540
    },
    "id": "jJqw1UIJXKcw"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "print(\"Testing the model...\")\n",
    "accuracy, far, frr = test_model(model, test_loader, device, threshold=threshold)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "print(f\"False Acceptance Rate (FAR): {far:.2f}\")\n",
    "print(f\"False Rejection Rate (FRR): {frr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMS6hmhGIvxW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
